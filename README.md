# GANå®éªŒè¯¦ç»†ä½¿ç”¨è¯´æ˜

## ç›®å½•
1. [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
2. [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
3. [è®­ç»ƒæ¨¡å‹](#è®­ç»ƒæ¨¡å‹)
4. [è¯„ä¼°æ¨¡å‹](#è¯„ä¼°æ¨¡å‹)
5. [ç”Ÿæˆå›¾åƒ](#ç”Ÿæˆå›¾åƒ)
6. [ç»“æœåˆ†æ](#ç»“æœåˆ†æ)
7. [è¶…å‚æ•°è°ƒä¼˜](#è¶…å‚æ•°è°ƒä¼˜)
8. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ç¯å¢ƒé…ç½®

### 1. å®‰è£…ä¾èµ–

```bash

# å®‰è£…PyTorchï¼ˆæ ¹æ®ä½ çš„CUDAç‰ˆæœ¬é€‰æ‹©ï¼‰
# CPUç‰ˆæœ¬
pip install torch torchvision

# GPUç‰ˆæœ¬ (CUDA 11.3)
pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu113

# å®‰è£…å…¶ä»–ä¾èµ–
pip install -r requirements.txt
```

### 2. éªŒè¯å®‰è£…

```python
import torch
print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
    print(f"GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")
```

---

## æ•°æ®å‡†å¤‡

### 1. ä¸‹è½½æ•°æ®é›†

**Anime Faceæ•°æ®é›†**:
- é“¾æ¥: https://www.modelscope.cn/datasets/yanghaitao/AnimeFace128
- å¤§å°: 57221å¼ åŠ¨æ¼«å¤´åƒ


### 2. ç»„ç»‡æ•°æ®ç›®å½•

å¯¹äºAnime Faceæ•°æ®é›†ï¼š
```
project/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ faces/           # æ³¨æ„ï¼šåªæœ‰ä¸€ä¸ªå­æ–‡ä»¶å¤¹
â”‚       â”œâ”€â”€ 0000fdee4208b8b7e12074c920bc6166-0.jpg
â”‚       â”œâ”€â”€ 0001a0fca4e9d2193afea712421693be-0.jpg
â”‚       â””â”€â”€ ...
â”œâ”€â”€ main.py
â”œâ”€â”€ model.py
â””â”€â”€ ...
```

**é‡è¦**: PyTorchçš„`ImageFolder`è¦æ±‚æ•°æ®ç›®å½•ä¸‹æœ‰è‡³å°‘ä¸€ä¸ªå­æ–‡ä»¶å¤¹ï¼

### 3. æ•°æ®éªŒè¯

```python
import torchvision as tv
from torch.utils.data import DataLoader

# æ£€æŸ¥æ•°æ®é›†
dataset = tv.datasets.ImageFolder('data/')
print(f"æ•°æ®é›†å¤§å°: {len(dataset)}")
print(f"ç±»åˆ«æ•°: {len(dataset.classes)}")

# æŸ¥çœ‹ä¸€å¼ å›¾ç‰‡
img, label = dataset[0]
print(f"å›¾ç‰‡å°ºå¯¸: {img.size}")
```

---

## è®­ç»ƒæ¨¡å‹

### 1. åŸºç¡€è®­ç»ƒ

```bash
# ä½¿ç”¨GPUè®­ç»ƒï¼Œå¯ç”¨å¯è§†åŒ–
python main.py train --gpu --vis=True

# ä½¿ç”¨CPUè®­ç»ƒï¼Œä¸å¯ç”¨å¯è§†åŒ–
python main.py train --nogpu --vis=False
```

### 2. å¯åŠ¨å¯è§†åŒ–æœåŠ¡ï¼ˆå¯é€‰ï¼‰

åœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œï¼š
```bash
python -m visdom.server
```

ç„¶ååœ¨æµè§ˆå™¨æ‰“å¼€: http://localhost:8097

### 3. è‡ªå®šä¹‰è®­ç»ƒå‚æ•°

```bash
# ç¤ºä¾‹1: å¿«é€Ÿæµ‹è¯•ï¼ˆå°‘é‡epochï¼‰
python main.py train --gpu --max_epoch=50 --save_every=5 --eval_every=5

# ç¤ºä¾‹2: å°batch sizeï¼ˆæ˜¾å­˜ä¸è¶³æ—¶ï¼‰
python main.py train --gpu --batch_size=64 --num_workers=2

# ç¤ºä¾‹3: å®Œæ•´è®­ç»ƒ
python main.py train --gpu \
    --batch_size=256 \
    --lr1=2e-4 \
    --lr2=2e-4 \
    --max_epoch=200 \
    --save_every=10 \
    --eval_every=5
```

### 4. è®­ç»ƒè¾“å‡ºè¯´æ˜

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šï¼š
- åœ¨`imgs/`ç›®å½•ä¿å­˜ç”Ÿæˆçš„å›¾åƒ
- åœ¨`checkpoints/`ç›®å½•ä¿å­˜æ¨¡å‹
- åœ¨`logs/`ç›®å½•ä¿å­˜è®­ç»ƒæ—¥å¿—
- åœ¨visdomç•Œé¢æ˜¾ç¤ºå®æ—¶æŸå¤±å’Œå›¾åƒï¼ˆå¦‚æœå¯ç”¨ï¼‰

```
è®­ç»ƒè¾“å‡ºç¤ºä¾‹ï¼š
Epoch 1/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195/195 [02:15<00:00,  1.44it/s]
Epoch 1 å®Œæˆ - D_loss: 1.3845, G_loss: 2.1234

å¼€å§‹è¯„ä¼°æ¨¡å‹...
Inception Score: 2.34 Â± 0.12
FID Score: 156.3
```

---

## è¯„ä¼°æ¨¡å‹

### 1. è®­ç»ƒä¸­è‡ªåŠ¨è¯„ä¼°

è¯„ä¼°ä¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªåŠ¨è¿›è¡Œï¼ˆæ¯`eval_every`ä¸ªepochï¼‰ï¼š
- è®¡ç®—Inception Score (IS)
- è®¡ç®—FrÃ©chet Inception Distance (FID)
- ç»“æœä¿å­˜åœ¨`logs/eval_metrics.txt`

### 2. å•ç‹¬è¯„ä¼°æ¨¡å‹

å¦‚æœä½ æƒ³è¯„ä¼°å·²ä¿å­˜çš„æ¨¡å‹ï¼š

```python
# åœ¨main.pyä¸­æ·»åŠ evaluateå‡½æ•°
import fire

def evaluate(**kwargs):
    """è¯„ä¼°å·²ä¿å­˜çš„æ¨¡å‹"""
    for k_, v_ in kwargs.items():
        setattr(opt, k_, v_)
    
    device = t.device('cuda') if opt.gpu else t.device('cpu')
    
    # åŠ è½½æ•°æ®
    transforms = tv.transforms.Compose([...])
    dataset = tv.datasets.ImageFolder(opt.data_path, transform=transforms)
    dataloader = t.utils.data.DataLoader(dataset, ...)
    
    # åŠ è½½æ¨¡å‹
    netg = NetG(opt)
    netg.load_state_dict(t.load(opt.netg_path))
    netg.to(device)
    
    # è¯„ä¼°
    metrics = evaluate_model(netg, dataloader, device, opt)
    print(f"IS: {metrics['is_mean']:.4f} Â± {metrics['is_std']:.4f}")
    print(f"FID: {metrics['fid']:.4f}")

# è¿è¡Œ
python main.py evaluate --gpu \
    --netg-path=checkpoints/netg_200.pth \
    --num_eval_samples=5000
```

### 3. ç†è§£è¯„ä¼°æŒ‡æ ‡

**Inception Score (IS)**:
- èŒƒå›´: 1~10+
- è¶Šé«˜è¶Šå¥½
- è¡¡é‡ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå¤šæ ·æ€§
- å¯¹äºåŠ¨æ¼«å¤´åƒï¼ŒIS > 3.5 é€šå¸¸è¡¨ç¤ºè¾ƒå¥½çš„è´¨é‡

**FID Score**:
- èŒƒå›´: 0~500+
- è¶Šä½è¶Šå¥½
- è¡¡é‡ç”Ÿæˆåˆ†å¸ƒä¸çœŸå®åˆ†å¸ƒçš„è·ç¦»
- å¯¹äºåŠ¨æ¼«å¤´åƒï¼ŒFID < 60 é€šå¸¸è¡¨ç¤ºè¾ƒå¥½çš„è´¨é‡

---

## ç”Ÿæˆå›¾åƒ

### 1. ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç”Ÿæˆ

```bash
# åŸºç¡€ç”Ÿæˆï¼ˆéœ€è¦é¢„å…ˆä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼‰
python main.py generate --gpu \
    --netd-path=checkpoints/netd_200.pth \
    --netg-path=checkpoints/netg_200.pth \
    --gen-img=result.png \
    --gen-num=64

# ç”Ÿæˆæ›´å¤šå›¾ç‰‡
python main.py generate --gpu \
    --netd-path=checkpoints/netd_200.pth \
    --netg-path=checkpoints/netg_200.pth \
    --gen-img=result_large.png \
    --gen-num=256 \
    --gen-search-num=2048
```

### 2. å‚æ•°è¯´æ˜

- `gen-num`: æœ€ç»ˆä¿å­˜çš„å›¾ç‰‡æ•°é‡
- `gen-search-num`: ç”Ÿæˆå€™é€‰å›¾ç‰‡çš„æ•°é‡ï¼ˆä¼šä»ä¸­é€‰å‡ºæœ€å¥½çš„ï¼‰
- `gen-mean`: å™ªå£°å‡å€¼ï¼ˆé»˜è®¤0ï¼‰
- `gen-std`: å™ªå£°æ ‡å‡†å·®ï¼ˆé»˜è®¤1ï¼‰

### 3. ç”Ÿæˆå¤šæ ·æ€§è°ƒæ•´

```bash
# æ›´éšæœºçš„ç”Ÿæˆï¼ˆå¢å¤§æ ‡å‡†å·®ï¼‰
python main.py generate --gpu \
    --netg-path=checkpoints/netg_200.pth \
    --netd-path=checkpoints/netd_200.pth \
    --gen-std=1.5

# æ›´é›†ä¸­çš„ç”Ÿæˆï¼ˆå‡å°æ ‡å‡†å·®ï¼‰
python main.py generate --gpu \
    --netg-path=checkpoints/netg_200.pth \
    --netd-path=checkpoints/netd_200.pth \
    --gen-std=0.7
```

---

## ç»“æœåˆ†æ

### 1. è¿è¡Œåˆ†æè„šæœ¬

```bash
python analyze.py
```

è¿™ä¼šç”Ÿæˆï¼š
- `analysis/training_curves.png` - è®­ç»ƒæŸå¤±æ›²çº¿
- `analysis/metrics_evolution.png` - ISå’ŒFIDæ¼”å˜
- `analysis/evolution_comparison.png` - ä¸åŒepochçš„å›¾åƒå¯¹æ¯”
- `analysis/hyperparameter_analysis.png` - è¶…å‚æ•°å½±å“åˆ†æ
- `analysis/best_samples.png` - æœ€ä½³ç”Ÿæˆæ ·æœ¬
- `analysis/summary_report.md` - å®éªŒæ€»ç»“

### 2. æŸ¥çœ‹è®­ç»ƒæ—¥å¿—

```python
import pandas as pd
import matplotlib.pyplot as plt

# è¯»å–æ—¥å¿—
df = pd.read_csv('logs/training_log.txt')

# ç»˜åˆ¶æŸå¤±æ›²çº¿
plt.figure(figsize=(10, 5))
plt.plot(df['D_Loss'], label='D Loss', alpha=0.7)
plt.plot(df['G_Loss'], label='G Loss', alpha=0.7)
plt.legend()
plt.show()
```

### 3. æŸ¥çœ‹è¯„ä¼°æŒ‡æ ‡

```bash
cat logs/eval_metrics.txt
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
Epoch 5: IS=2.34Â±0.12, FID=156.3
Epoch 10: IS=2.67Â±0.15, FID=124.5
Epoch 15: IS=2.98Â±0.14, FID=102.3
...
```

---

## è¶…å‚æ•°è°ƒä¼˜

### 1. å­¦ä¹ ç‡è°ƒä¼˜

```bash
# å®éªŒ1: ä½å­¦ä¹ ç‡
python main.py train --gpu --lr1=1e-4 --lr2=1e-4 --env=GAN_lr_low

# å®éªŒ2: æ ‡å‡†å­¦ä¹ ç‡
python main.py train --gpu --lr1=2e-4 --lr2=2e-4 --env=GAN_baseline

# å®éªŒ3: é«˜å­¦ä¹ ç‡
python main.py train --gpu --lr1=5e-4 --lr2=5e-4 --env=GAN_lr_high
```

### 2. Batch Sizeè°ƒä¼˜

```bash
# å®éªŒ1: å°batch
python main.py train --gpu --batch_size=64 --env=GAN_bs64

# å®éªŒ2: ä¸­batch
python main.py train --gpu --batch_size=128 --env=GAN_bs128

# å®éªŒ3: å¤§batch
python main.py train --gpu --batch_size=256 --env=GAN_bs256
```

### 3. è®­ç»ƒé¢‘ç‡è°ƒä¼˜

```bash
# å®éªŒ1: é¢‘ç¹æ›´æ–°ç”Ÿæˆå™¨
python main.py train --gpu --d_every=1 --g_every=1 --env=GAN_freq_1_1

# å®éªŒ2: å¹³è¡¡æ›´æ–°ï¼ˆæ¨èï¼‰
python main.py train --gpu --d_every=1 --g_every=5 --env=GAN_freq_1_5

# å®éªŒ3: å°‘æ›´æ–°ç”Ÿæˆå™¨
python main.py train --gpu --d_every=1 --g_every=10 --env=GAN_freq_1_10
```

### 4. ç½‘ç»œå®¹é‡è°ƒä¼˜

```bash
# å®éªŒ1: å°ç½‘ç»œ
python main.py train --gpu --ngf=32 --ndf=32 --env=GAN_small

# å®éªŒ2: æ ‡å‡†ç½‘ç»œ
python main.py train --gpu --ngf=64 --ndf=64 --env=GAN_baseline

# å®éªŒ3: å¤§ç½‘ç»œ
python main.py train --gpu --ngf=128 --ndf=128 --env=GAN_large
```

### 5. è®°å½•å®éªŒç»“æœ

åˆ›å»º`logs/hyperparameter_experiments.csv`ï¼š
```csv
experiment,lr_g,lr_d,batch_size,g_every,nz,ngf,ndf,IS,FID,notes
baseline,2e-4,2e-4,256,5,100,64,64,3.89,52.1,æœ€ä½³é…ç½®
lr_low,1e-4,1e-4,256,5,100,64,64,3.45,72.3,è®­ç»ƒç¨³å®šä½†æ…¢
lr_high,5e-4,5e-4,256,5,100,64,64,2.98,95.6,è®­ç»ƒä¸ç¨³å®š
...
```

---

## å¸¸è§é—®é¢˜

### 1. CUDAå†…å­˜ä¸è¶³

**é—®é¢˜**: `RuntimeError: CUDA out of memory`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å‡å°batch size
python main.py train --gpu --batch_size=64

# å‡å°workeræ•°é‡
python main.py train --gpu --num_workers=2

# ä½¿ç”¨CPUï¼ˆå¦‚æœGPUå†…å­˜çœŸçš„ä¸å¤Ÿï¼‰
python main.py train --nogpu --batch_size=128
```

### 2. è®­ç»ƒä¸ç¨³å®š

**ç—‡çŠ¶**: æŸå¤±å‰§çƒˆæ³¢åŠ¨ï¼Œç”Ÿæˆè´¨é‡æ—¶å¥½æ—¶å

**è§£å†³æ–¹æ¡ˆ**:
- é™ä½å­¦ä¹ ç‡: `--lr1=1e-4 --lr2=1e-4`
- è°ƒæ•´è®­ç»ƒé¢‘ç‡: `--g_every=10`
- å‡å°batch size: `--batch_size=128`

### 3. æ¨¡å¼å´©æºƒ

**ç—‡çŠ¶**: ç”Ÿæˆå™¨åªç”Ÿæˆå°‘æ•°å‡ ç§ç›¸ä¼¼çš„å›¾åƒ

**è§£å†³æ–¹æ¡ˆ**:
- å¢åŠ åˆ¤åˆ«å™¨è®­ç»ƒé¢‘ç‡: `--d_every=1 --g_every=5`
- å°è¯•ä¸åŒçš„å­¦ä¹ ç‡æ¯”ä¾‹: `--lr1=1e-4 --lr2=2e-4`
- å¢åŠ å™ªå£°ç»´åº¦: `--nz=200`

### 4. ç”Ÿæˆå›¾åƒæ¨¡ç³Š

**ç—‡çŠ¶**: å›¾åƒç¼ºä¹ç»†èŠ‚ï¼Œçœ‹èµ·æ¥æ¨¡ç³Š

**è§£å†³æ–¹æ¡ˆ**:
- å¢åŠ è®­ç»ƒè½®æ•°: `--max_epoch=300`
- å¢åŠ ç½‘ç»œå®¹é‡: `--ngf=128 --ndf=128`
- è°ƒæ•´å­¦ä¹ ç‡: `--lr1=1e-4`

### 5. è®­ç»ƒé€Ÿåº¦æ…¢

**é—®é¢˜**: è®­ç»ƒæ—¶é—´è¿‡é•¿

**ä¼˜åŒ–æ–¹æ¡ˆ**:
```bash
# å¢åŠ num_workersï¼ˆæ•°æ®åŠ è½½å¹¶è¡Œï¼‰
python main.py train --gpu --num_workers=8

# ä½¿ç”¨æ›´å¤§çš„batch sizeï¼ˆå¦‚æœæ˜¾å­˜å…è®¸ï¼‰
python main.py train --gpu --batch_size=512

# å‡å°‘è¯„ä¼°é¢‘ç‡
python main.py train --gpu --eval_every=10

# ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆéœ€è¦ä¿®æ”¹ä»£ç ï¼‰
# åœ¨è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨torch.cuda.amp
```

### 6. Visdomå¯è§†åŒ–é—®é¢˜

**é—®é¢˜**: æ— æ³•è¿æ¥åˆ°VisdomæœåŠ¡å™¨

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ç¡®ä¿VisdomæœåŠ¡æ­£åœ¨è¿è¡Œ
python -m visdom.server

# å¦‚æœç«¯å£è¢«å ç”¨ï¼Œæ›´æ”¹ç«¯å£
python -m visdom.server -port 8098

# åœ¨è®­ç»ƒæ—¶æŒ‡å®šç«¯å£
python main.py train --gpu --vis=True --port=8098

# æˆ–è€…å…³é—­å¯è§†åŒ–
python main.py train --gpu --vis=False
```

### 7. æ•°æ®åŠ è½½é”™è¯¯

**é—®é¢˜**: `RuntimeError: Found 0 files in subfolders`

**åŸå› **: ImageFolderè¦æ±‚æ•°æ®ç›®å½•ä¸‹æœ‰å­æ–‡ä»¶å¤¹

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ­£ç¡®çš„ç›®å½•ç»“æ„
data/
â””â”€â”€ faces/          # å¿…é¡»æœ‰è¿™ä¸ªå­æ–‡ä»¶å¤¹
    â”œâ”€â”€ img1.jpg
    â””â”€â”€ img2.jpg

# é”™è¯¯çš„ç›®å½•ç»“æ„
data/
â”œâ”€â”€ img1.jpg       # ä¸èƒ½ç›´æ¥æ”¾åœ¨dataä¸‹
â””â”€â”€ img2.jpg
```

---

## è¿›é˜¶æŠ€å·§

### 1. æ–­ç‚¹ç»­è®­

```python
# åœ¨main.pyä¸­ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
python main.py train --gpu \
    --netd-path=checkpoints/netd_100.pth \
    --netg-path=checkpoints/netg_100.pth
```

### 2. å­¦ä¹ ç‡è¡°å‡

åœ¨è®­ç»ƒä»£ç ä¸­æ·»åŠ å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼š
```python
scheduler_g = torch.optim.lr_scheduler.StepLR(optimizer_g, step_size=50, gamma=0.5)
scheduler_d = torch.optim.lr_scheduler.StepLR(optimizer_d, step_size=50, gamma=0.5)

# åœ¨æ¯ä¸ªepochå
scheduler_g.step()
scheduler_d.step()
```

### 3. æ¢¯åº¦è£å‰ª

é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼š
```python
torch.nn.utils.clip_grad_norm_(netg.parameters(), max_norm=5.0)
torch.nn.utils.clip_grad_norm_(netd.parameters(), max_norm=5.0)
```

### 4. æ—©åœæ³•

```python
best_fid = float('inf')
patience = 20
counter = 0

if fid < best_fid:
    best_fid = fid
    counter = 0
    # ä¿å­˜æœ€ä½³æ¨¡å‹
else:
    counter += 1
    if counter >= patience:
        print("Early stopping!")
        break
```

---

## å®éªŒå»ºè®®

### åˆå­¦è€…æµç¨‹
1. å…ˆç”¨å°æ•°æ®é›†å’Œå°‘é‡epochæµ‹è¯•ï¼ˆå¦‚50ä¸ªepochï¼‰
2. ç¡®è®¤ä»£ç èƒ½æ­£å¸¸è¿è¡Œåï¼Œå†è¿›è¡Œå®Œæ•´è®­ç»ƒ
3. å…³æ³¨ISå’ŒFIDæŒ‡æ ‡çš„å˜åŒ–è¶‹åŠ¿
4. ä¿å­˜å¤šä¸ªcheckpointä»¥ä¾¿å¯¹æ¯”

### å®Œæ•´å®éªŒæµç¨‹
1. **Baselineè®­ç»ƒ** (2-3å°æ—¶): ä½¿ç”¨é»˜è®¤å‚æ•°è®­ç»ƒ200 epoch
2. **è¶…å‚æ•°è°ƒä¼˜** (6-8å°æ—¶): æµ‹è¯•ä¸åŒå­¦ä¹ ç‡ã€batch sizeç­‰
3. **ç»“æœåˆ†æ** (1å°æ—¶): è¿è¡Œåˆ†æè„šæœ¬ï¼Œç”Ÿæˆå›¾è¡¨
4. **æ’°å†™æŠ¥å‘Š** (2-3å°æ—¶): åŸºäºæ¨¡æ¿å®Œæˆå®éªŒæŠ¥å‘Š

### æ¨èé…ç½®
- GPU: NVIDIA GTX 1080 Ti æˆ–æ›´å¥½
- æ˜¾å­˜: è‡³å°‘ 8GB
- å†…å­˜: è‡³å°‘ 16GB
- è®­ç»ƒæ—¶é—´: çº¦ 2-3 å°æ—¶ (200 epochs)

---

## èµ„æºé“¾æ¥

- **PyTorchæ–‡æ¡£**: https://pytorch.org/docs/
- **DCGANè®ºæ–‡**: https://arxiv.org/abs/1511.06434
- **GANæ•™ç¨‹**: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html
- **Visdomæ–‡æ¡£**: https://github.com/fossasia/visdom

---

## è”ç³»ä¸åé¦ˆ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·ï¼š
1. æŸ¥çœ‹å¸¸è§é—®é¢˜éƒ¨åˆ†
2. æ£€æŸ¥æ—¥å¿—æ–‡ä»¶ä¸­çš„é”™è¯¯ä¿¡æ¯
3. åœ¨GitHubä¸Šæissue

ç¥å®éªŒé¡ºåˆ©ï¼ğŸ‰
